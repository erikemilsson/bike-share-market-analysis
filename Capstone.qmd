---
title: "Case Study: How Does a Bike-Share Navigate Speedy Success?"
author: "Erik Emilsson"
date: "20 December 2022"
toc: true
toc-depth: 2
format:
  html:
    code-fold: true
---

*This project is part of the Google Data Analytics Certificate on Coursera and the dataset and the fictional problem comes from Track 1 How does a bike-share navigate speedy business. I used SQL for data appending the datasets and R for data import, cleaning and visualization as well as the final reporting.*

# 1. Introduction & Business Objectives

Cyclist is a bike/share program with over 5,800 bikes and 600 docking stations. Currently there are two types of riders: 

1. casual riders (those who buy single-ride or full-day passes), and 
2. annual members a.k.a. Cyclistic members. 

The goal is to *maximize the number of annual memberships for the company by converting more casual riders to annual members*. Lily Moreno (director of marketing) and the Cyclistic finance analysts have concluded that that annual members are more profitable than casual riders. Before this, Cyclistic have focused on building general awareness and appealing to broad consumer segments.

Currently 8 percent of riders use assistive options (e.g. reclining bikes, hand tricycles, and cargo bikes) while the rest use traditional bikes. Those who use traditional bikes are more likely to be casual riders, but about 30 percent of them use the service to commute to work each day.

Of the the following three questions that will guide the larger scope of the future marketing program, this report will only answer the first question:

* How do annual members and casual riders use Cyclistic bikes differently?
* Why would casual riders buy Cyclistic annual memberships?
* How can Cyclistic use digital media to influence casual riders to become annual members?

The stakeholders are:

* Lily Moreno, director of marketing and my fictional manager,
* The Cyclistic marketing analytics team (which I am part of), which supports the Cyclistic marketing strategy with data, and
* The Cyclistic executive team that will decide if the recommended marketing program is approved or not.
  
# 2. Data Preparation

```{r Import Libraries, message=FALSE, warning=FALSE}
# Import Libraries
library(tidyverse)
library(skimr)
library(janitor)
library(lubridate)
library(openxlsx)
library(anytime)
library(ggridges)
library(plotly)
library(bigrquery)
library(googleAuthR)
```


The dataset to represent Cyclistic bike share service bike data comes from Divvy, Lyft and Scooters, LLC ("Bikeshare") data. See the licence agreement for more information https://ride.divvybikes.com/data-license-agreement. 

The past 12 months (March 2022 to Febuary 2023) of historical trip data was downloaded from the database in CSV format to a Google Drive location, then uploaded to BigQuery. After this, the 12 files were appended and finally exported as a CSV file to be read into this R Markdown report. Apart from appending the data, the SQL query essentially left the data unchanged so I could showcase the data cleaning process in R, however, in practice it should be more practical and efficient to do some of these steps in the SQL query instead.

```{r Data Import, message=FALSE}
# Authenticate with Google Cloud
options(googleAuthR.scopes.selected = "https://www.googleapis.com/auth/bigquery")
googleAuthR::gar_auth()

# Set up your project ID
project_id <- "firm-solution-376302"

# Write your SQL query
SQL_query <- "
  SELECT *
  FROM `CyclisticBikes202311_202410.table_narrow_202311_202410`
  LIMIT 100
"

# Execute the query
query_job <- bq_project_query(project_id, SQL_query)

# Download the result into an R data frame
df <- bq_table_download(query_job)

# Display the first few rows of the data frame
head(df)
```



# 3. Exploratory Data Analysis & Cleaning

First the headers are renamed to make them clearer. Then the date columns are converted to the datetime format. The start dates are extracted then extracted from the datetime columns, and a trip time column is calculated by taking the difference from the start and the end datetimes. The riginal datetime columns are then removed.

```{r Rename headers, echo=FALSE, message=FALSE}
df_1 <- df %>% 
  rename(Ride_ID = ride_id) %>%
  rename(Bike_Type = rideable_type) %>%
  rename(Start_Date_and_Time = started_at) %>%
  rename(End_Date_and_Time = ended_at) %>%
  rename(Start_Station_Name = start_station_name) %>%
  rename(Start_Station_ID = start_station_id) %>%
  rename(End_Station_Name = end_station_name) %>%
  rename(End_Station_ID = end_station_id) %>%
  rename(Rider_Type = member_casual) %>%
  rename(Start_Latitude = start_lat) %>%
  rename(Start_Longitude = start_lng) %>%
  rename(End_Latitude = end_lat) %>%
  rename(End_Longitude = end_lng) 
```

```{r parse datetime column, add start date column and add trip time columns}
df_2 <- df_1 %>%
  mutate(
    Start_Date = date(Start_Date_and_Time),
    Start_Date_and_Time = anytime(Start_Date_and_Time, tz = "UTC"),
    End_Date_and_Time = anytime(End_Date_and_Time, tz = "UTC"),
    Trip_Time_Minutes = difftime(End_Date_and_Time, 
                                 Start_Date_and_Time, units="mins")
    )
```

```{r save new df as backup, include=FALSE}
df_3 <- df_2
```

Since the trip times and the starting dates have been "extracted" from the original datetime columns, the original columns can be removed.

```{r Remove date-time columns}
df_3 <- select(df_3, -c(Start_Date_and_Time, End_Date_and_Time))
```

Some Trip_Time_Minutes values are negative, which doesn't make sense. These negative observations will be removed and additionally any trip times that areunder 2 minutes will also be removed to make sure that the trips were intentional by the rider.

```{r}
paste(sum(df_3$Trip_Time_Minutes < 2),
      "rows with trip times below 0 minutes have been removed, equal to ", 
      round(100*(sum(df_3$Trip_Time_Minutes < 2))/(nrow(df_3)),1), 
      "% of all trips.")

df_clean <- df_3 %>%
  filter(Trip_Time_Minutes > 2) #removes rows below 0 minutes
```

Now to look at missing values and unique values from the cleaned dataset, as well as some statistics by using the skim function.

```{r Skim dataframe}
df_skim <- skim_without_charts(df_clean) %>%
  print()
```


```{r Information about missing values}
df_skim %>%
  ggplot(mapping = aes(x = 100*complete_rate, y = skim_variable)) +
  geom_bar(stat= "identity", fill="azure3") +
  labs(
    title="Data completeness per column", 
    subtitle = "Station Names and IDs have missing data!",
    x = "Completeness [%]", 
    y = ""
    ) +
  theme_bw() + 
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, color = "black", 
                                 size = 10, face = "bold",)
    ) +
  geom_text(aes(label = round(100*complete_rate, digits = 0)), 
            position = position_stack(vjust = 0.97))
```
* Between 15-17% of the data is missing for the start and end station names and 
  IDs. 
  
From the skim function output the following information about *unique* observations can be seen:

* There are a total of 5,829,084 observations that each have unique Ride_IDs.
* Bike_Type has 3 unique values 
* Rider_Type has 2 unique values.
* Start and end station names have close to 1700 unique values
* Start and end IDs have close to 1300 unique values.

The unique values of all the locations are much greater than the "over 600 docking station" that were stated in the case study description. Start/End station ID come closest (1302 and 1309 unique values). This divergence merits an investigation, but will not be the focus of this analysis.

The location IDs consist of a code while the location names are either one or two street names (presumably their intersection) with a "&" symbol as their denominator. There are more unique location names than location IDs, which could be for a variety or reasons. It could be misspellings, it could be due to some street names being in reverse order, or it could perhaps be due to there being more than one station per intersection. Again, delving deeper into the geographical data is not the focus of this analysis as this is instead something that I might ask a data engineer for more information in a real world problem. However, to make sure I do my due diligence in this analysis, I will export the unique values to Excel and show my observations and recommendations here.

```{r duplicate start street names, eval=FALSE, include=FALSE}
uniqueStartStations <- df_3 %>%
  select(Start_Station_ID, Start_Station_Name) %>%
  distinct()
```

```{r duplicate end street names, eval=FALSE, include=FALSE}
uniqueEndStations <- df_3 %>%
  select(End_Station_ID, End_Station_Name) %>%
  distinct()
```

```{r List occurences >1 of Start_Station_Names for UniqueStartStations, eval=FALSE, include=FALSE}
n_occur <- data.frame(table(uniqueStartStations$Start_Station_Name))
n_occur[n_occur$Freq > 1,]
```

```{r List occurences >1 of Start_Station_IDs for UniqueStartStations, eval=FALSE, include=FALSE}
n_occur <- data.frame(table(uniqueStartStations$Start_Station_ID))
n_occur[n_occur$Freq > 1,]
```

```{r List occurences >1 of End_Station_Names for UniqueEndStations, eval=FALSE, include=FALSE}
n_occur <- data.frame(table(uniqueEndStations$End_Station_Name))
n_occur[n_occur$Freq > 1,]
```

```{r List occurences >1 of End_Station_IDs for UniqueEndStations, eval=FALSE, include=FALSE}
n_occur <- data.frame(table(uniqueEndStations$End_Station_ID))
n_occur[n_occur$Freq > 1,]
```

```{r create Excel sheet to investigate unique occurences of station names and IDs, eval=FALSE, include=FALSE}
Start_stations <- createWorkbook()
addWorksheet(Start_stations, "First_Sheet")
writeData(Start_stations,"First_Sheet", uniqueStartStations)
saveWorkbook(Start_stations, file = "Start_stations_unique.xlsx", overwrite = TRUE)
```

From the investigation I found that:
* There are 17 duplicate start station names (for station ID)
* There are 341 duplicate start station IDs (for staion names)
* There are 17 duplicate end station names (for station ID)
* There are 351 duplicate end station IDs (for station names)
* Station ID codes are sometimes text e.g. street names

The overlap likely means that there are many locations that should be aggregated into just one if a fair comparison were to be done for the counts of rides per location. For this reason, also due to the ~15% missing values, there is significant bias when using this data, which should be kept in mind when looking at the results so as to not make conclusions and decisions on this misleading data. 

# 4. Analysis & Findings

## 4a. How are the different bike types used by members and non-members?

By splitting up the casual riders and members, and splitting up the three type of bike types (classic bikes, docked bikes, and electric bikes) we can compare them by how many trips each makes a year:

```{r Annual count of rides}
df_clean %>%
  ggplot() +
  geom_bar(mapping = aes(Bike_Type, fill = Bike_Type), color = "black") +
  facet_wrap(~Rider_Type) +
  labs(title="Annual rides per bike and rider type", x = "", y = "Rides [count]") +
  theme(plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"))
```
Observations:

* There are more total rides from members than for casual riders.
* Casual riders prefer to take more electric bike rides than classic bike rides by a small margin, while it is the opposite for members.
* There are about twice as many classic bike rides for casual riders as for members. 
* Electric bikes are used about the same amount of times by casual riders and members.
* Docked bikes were not used at all by members.
* Docked bikes are used much less often than any other type of bike.

## 4b. How is the trip time different for members and non-members?

To get some stats on the trip time I'll create a table and a boxplot of the ride times.

```{r trip time stats}
df_clean %>%
  group_by(Rider_Type, Bike_Type) %>%
  summarise(min = min(Trip_Time_Minutes), 
            max = max(Trip_Time_Minutes),
            mean = mean(Trip_Time_Minutes),
            median = median(Trip_Time_Minutes),
            "standard deviation" = sd(Trip_Time_Minutes)
            )
```

```{r boxplot trip times, message=FALSE, warning=FALSE}
df_clean %>%
  ggplot(aes(x=Rider_Type, y=Trip_Time_Minutes, fill=Bike_Type)) +
  geom_boxplot() +
  facet_wrap(~Rider_Type) +
  labs(title="Annual ride times per bike and rider type", 
       x = "", 
       y = "duration [minutes]") +
  theme(plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"))
```

The boxplot wasn't very helpful since the spread of the docked bike rides is so wide. I'll instead do a plot of only the mean times, keeping in mind that the large spread for some of the values.

```{r Annual mean ride times, message=FALSE}
df_clean %>%
  group_by(Rider_Type, Bike_Type) %>%
  summarise(mean = mean(Trip_Time_Minutes), n= n()) %>%
  ggplot(mapping = aes(x = Bike_Type, 
                       y = mean,
                       fill = Bike_Type)) +
  geom_bar(stat= "identity", color = "black") +
  facet_wrap(~Rider_Type) +
  labs(title="Annual Mean ride times per bike and rider type", 
       x = "", 
       y = "duration [minutes]") +
  theme(plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"))
```

This shows that although there aren't as many docked bikes as other types of bikes, the total annual ride time is about 4-6 times higher. Also casual riders use bikes for longer than members, especially for classic bikes (about twice as long on average).

```{r trip time distribution first hour, message=FALSE, warning=FALSE}
ggplot(df_clean,
       aes(x = Trip_Time_Minutes,
           y = Bike_Type,
           fill = Bike_Type)
       ) +
  scale_x_continuous(limits=c(0, 60)) +
  geom_density_ridges() + 
  facet_wrap(~Rider_Type, ncol = 1) +
  theme_ridges() +
  labs(title = "Distribution of trip times under 1 hour", 
       x = "Trip time [minutes]", y = "Ride count distribution") +
  theme(plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"))
```

This last graph for the distribution of times shows that the docked bike ride times are spread out much more than other bike rides. 

## 4c. How are the bikes used throughout the year?

Now to plot the distribution of rides throughout the year, divided again into casual riders and members, as well as bike types.

```{r trip time distribution over year}
ggplot(df_clean, 
       aes(x = Start_Date, 
           fill = Bike_Type)) +
  geom_density(alpha = 0.4) +
  scale_x_date(date_breaks = "1 months", date_labels = "%b %d") +
  facet_wrap(~Rider_Type, ncol = 1) +
  labs(title = "Trips distribution per day of the year", 
       x = "Trip day", y = "") +
  theme(axis.text.y=element_blank(),  #remove y axis labels
        axis.ticks.y=element_blank()  #remove y axis ticks
        ) +
  theme(plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"))
```

* Bike usage is in general higher between May-November and lower between November-May.
* Electric bike rides seem to be used most in the months of July-October.
* Classic and docked bikes overlap more, and are used most in the months of May-Aug.
* Members have a more even distribution of usage for throughout the year compared to casual riders. Essentially, the cooler months of September-May casual riders use the service less relative to members while in the warmer months June-October they use the bikes more relative to members.

As the summer months are where most casual riders are using the bikes, there could be an opportunity to run campaigns during these months to hook them for the year.

## 4d. Where are the bikes being used?

Since there are a lot of datapoints I will split the whole dataset into a samples of 10000 points of data for casual riders and members, as well as different bike types, to see how they differ in the locations in which the rides start from.

(By clicking the legend we can turn on or off the markers from the map)

```{r map casual and member}
df_clean_map <- df_clean %>% 
  select(Rider_Type, 
         Bike_Type, 
         Start_Longitude, 
         Start_Latitude)


fig <- plot_ly(df_clean_map %>% sample_n(100000),
    lat = ~Start_Latitude,
    lon = ~Start_Longitude,
    marker = list(size = 6, opacity = 0.2),
    type = 'scattermapbox',
    colors = "Set1",
    color = (~Rider_Type)
    ) %>%
  config(displayModeBar = FALSE) %>%
  layout(
    mapbox = list(
      style = 'carto-positron',
      zoom = 8,
      center = list(lon = -87.63, lat = 41.88)))  

fig
```

There is quite a lot of overlap between casual riders and members, so this this map doesn't really give any new insights. Looking at the bike types gives something interesting to go on however.

```{r}
fig <- plot_ly(df_clean_map %>% sample_n(100000),
    lat = ~Start_Latitude,
    lon = ~Start_Longitude,
    marker = list(size = 6, opacity = 0.2),
    type = 'scattermapbox',
    colors = "Set1",
    color = (~Bike_Type)
    ) %>%
  config(displayModeBar = FALSE) %>%
  layout(
    mapbox = list(
      style = 'carto-positron',
      zoom = 8,
      center = list(lon = -87.63, lat = 41.88)))  

fig
```

The markers for the docked bike are much more centralized than both classic and electric bikes. The classic bikes have more spread, but the electric bikes have the most spread of all especially throughout western and southern parts of Chicago.

# 5. Recommendations & Insights

From the analysis I found these to be the most pressing calls to action for Cyclistic:

* Talk to data engineers to see if there is anything that can be done about the missing and incorrect labelling of the station IDs and names, as it currently makes the data to biased to use without risking making bad decisions on it.
* Look into how memberships for docked bike users currently work and if there is any way to simplify and clarify the process to these riders.
* Since docked bike users use bikes for long times, see if that fact can be used to attract them into buying a membership.
* Perform interviews or a questionnaire with casual riders to find out more about why they mostly prefer electric bikes to classic bike, and what it would take for them to get a membership.
* Run campaigns during the months of heavy casual rider bike use, during the months of May-November.